# **üõ°Ô∏è NeuralGraphDB v1.0: Roadmap de Ingenier√≠a y Rigor Acad√©mico**

Este documento detalla la transici√≥n de la arquitectura actual (v0.9) a la **v1.0**, optimizada para el estado del arte en IA y publicaci√≥n cient√≠fica.

## **üìä Evaluaci√≥n de Estado: v0.9 vs v1.0**

| Dimensi√≥n | Estado Actual (v0.9) | Requisito v1.0 (Academic Ready) |
| ----- | ----- | ----- |
| **Almacenamiento** | CSR H√≠brido (Est√°tico \+ Listas Delta) | **PCSR (Packed Compressed Sparse Row)** |
| **B√∫squeda Vectorial** | √çndice HNSW como "Sidecar" externo | **Semianillo Neural (HNSW as Matrix)** |
| **Hardware** | Optimizaci√≥n de CPU b√°sica | **SIMD Intrinsics (AVX-512 / NEON)** |
| **GraphRAG** | Traves√≠as Cypher b√°sicas | **Detecci√≥n de Comunidades (Leiden) Nativa** |

## **üèóÔ∏è √âpica 1: Sustrato Din√°mico (PCSR & PMA)**

**Objetivo:** Implementar la estructura de datos que permite actualizaciones en tiempo real manteniendo la velocidad de escaneo lineal de una matriz compacta.

### **Sprint 1: El Motor PMA (Packed Memory Array)**

* **An√°lisis de Arquitectura:** Analizar la implementaci√≥n actual del sistema de archivos y memoria en el prototipo v0.9 para evaluar c√≥mo la introducci√≥n del PMA afectar√° la gesti√≥n de punteros y la serializaci√≥n actual.  
* **User Story 1.1:** Como motor de almacenamiento, quiero gestionar un array con "gaps" (espacios) que se rebalanceen autom√°ticamente para permitir inserciones en $O(\\log^2 N)$ sin reescribir todo el buffer.  
* **Criterios de Aceptaci√≥n:**  
  * Implementaci√≥n de l√≥gica de densidad por segmentos (Upper/Lower density thresholds).  
  * Funci√≥n de `rebalance()` eficiente en Rust.  
* **Output T√©cnico:** M√≥dulo `neural-storage::pma` probado con 10M de inserciones aleatorias.

### **Sprint 2: Integraci√≥n PCSR Unificada**

* **An√°lisis de Arquitectura:** Evaluar el impacto de eliminar las listas de adyacencia din√°micas en el c√≥digo del `EdgeStore` y c√≥mo la unificaci√≥n en el PMA alterar√° los m√©todos de lectura/escritura concurrentes.  
* **User Story 1.2:** Como desarrollador, quiero eliminar las listas de adyacencia din√°micas y unificar todos los "edges" en el sustrato PMA para evitar *cache misses*.  
* **Criterios de Aceptaci√≥n:**  
  * Refactorizaci√≥n del `EdgeStore` para usar el offset del PMA.  
  * Benchmark comparativo: Reducci√≥n del 40% en latencia de traves√≠a vs v0.9.  
* **Output T√©cnico:** Integraci√≥n de `pma` en el core de `neural-core`.

## **üß† √âpica 2: Kernel Neural-Algebraico (GraphBLAS Unified)**

**Objetivo:** Unificar la geometr√≠a (vectores) con la topolog√≠a (grafos) mediante √°lgebra lineal.

### **Sprint 3: Implementaci√≥n de Semianillos Neurales**

* **An√°lisis de Arquitectura:** Analizar el ejecutor de consultas actual (`neural-executor`) para identificar los puntos de integraci√≥n de los nuevos operadores de semianillo y evaluar la compatibilidad con el sistema de tipos de NGQL.  
* **User Story 2.1:** Como motor de consultas, quiero ejecutar b√∫squedas vectoriales HNSW como si fueran una multiplicaci√≥n de matriz dispersa por vector (SpMV) usando un semianillo personalizado.  
* **Criterios de Aceptaci√≥n:**  
  * Definici√≥n de operadores $(\\oplus \= \\text{Top-K}, \\otimes \= \\text{Distancia})$.  
  * Compatibilidad con el ejecutor de queries NGQL.  
* **Output T√©cnico:** M√≥dulo `neural-algebra::semirings::neural`.

### **Sprint 4: Aceleraci√≥n SIMD con `faer`**

* **An√°lisis de Arquitectura:** Evaluar qu√© kernels algebraicos actuales son cr√≠ticos para el rendimiento y determinar qu√© secciones del c√≥digo de `faer` requieren integraci√≥n directa con instrucciones AVX-512/NEON.  
* **User Story 2.2:** Como sistema de alto rendimiento, quiero que las operaciones matriciales utilicen instrucciones de hardware espec√≠ficas (AVX-512) para maximizar el throughput.  
* **Criterios de Aceptaci√≥n:**  
  * Kernels de `faer` optimizados para la estructura PCSR.  
  * Incremento verificado de 3x en operaciones de agregaci√≥n.  
* **Output T√©cnico:** Optimizaci√≥n de `neural-executor` para hardware espec√≠fico.

## **üï∏Ô∏è √âpica 3: Advanced GraphRAG & Analytics**

**Objetivo:** Proveer las herramientas de an√°lisis global necesarias para agentes de IA modernos.

### **Sprint 5: Algoritmo de Leiden Nativo**

* **An√°lisis de Arquitectura:** Analizar la arquitectura de concurrencia actual para asegurar que la implementaci√≥n paralela de Leiden no genere condiciones de carrera en el acceso al PCSR din√°mico.  
* **User Story 3.1:** Como analista de IA, quiero ejecutar detecci√≥n de comunidades jer√°rquicas (Leiden) directamente en la matriz para agrupar informaci√≥n contextual.  
* **Criterios de Aceptaci√≥n:**  
  * Implementaci√≥n paralela del algoritmo sobre el PCSR.  
  * Soporte para grafos pesados (weighted graphs).  
* **Output T√©cnico:** M√≥dulo `neural-algorithms::community::leiden`.

### **Sprint 6: Pipeline de Resumen de Contexto**

* **An√°lisis de Arquitectura:** Evaluar el dise√±o del Parser y el generador de planes de ejecuci√≥n para incorporar la nueva funci√≥n `SUMMARIZE` sin romper la compatibilidad con el est√°ndar Cypher actual.  
* **User Story 3.2:** Como agente de IA, quiero que el motor genere autom√°ticamente un "Subgrafo de Conocimiento" (Knowledge Subgraph) basado en una consulta h√≠brida.  
* **Criterios de Aceptaci√≥n:**  
  * Funci√≥n `SUMMARIZE` en NGQL que extrae top-nodes y relaciones clave.  
  * Integraci√≥n con buffers de contexto para LLMs.  
* **Output T√©cnico:** Nueva funcionalidad en el Parser y Executor de NGQL.

## **üß™ √âpica 4: Validation y Benchmarking (The Paper)**

**Objetivo:** Obtener los datos emp√≠ricos para la publicaci√≥n cient√≠fica.

### **Sprint 7: Benchmark LDBC y Rigor Comparativo**

* **An√°lisis de Arquitectura:** Analizar las m√©tricas de instrumentaci√≥n actuales para asegurar que la captura de datos (latencia, memoria, write amplification) sea precisa y no introduzca un sesgo significativo en los resultados del benchmark.  
* **User Story 4.1:** Como investigador, necesito datos de rendimiento estandarizados contra Neo4j y FalkorDB para validar las tesis del paper.  
* **Criterios de Aceptaci√≥n:**  
  * Ejecuci√≥n completa de la suite LDBC Social Network Benchmark.  
  * Gr√°ficas de "Write Amplification" comparando PCSR vs CSR.  
* **Output T√©cnico:** Dataset de resultados `.csv` y suite de tests de estr√©s.

## **üõ†Ô∏è Gu√≠a de Evaluaci√≥n para el Equipo**

Al revisar el c√≥digo actual, los desarrolladores deben responder:

1. **Concurrencia:** ¬øEl actual `RwLock` de los indices escala con el nuevo PMA?  
2. **Alineaci√≥n de Memoria:** ¬øEstamos asegurando que los segmentos del PMA est√©n alineados a l√≠neas de cach√© (64 bytes)?  
3. **Abstracci√≥n de faer:** ¬øEstamos usando las APIs de bajo nivel de `faer` o estamos dejando que el compilador autovectorice? (Se prefiere control expl√≠cito para el paper).

